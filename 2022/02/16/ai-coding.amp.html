<!DOCTYPE html>
<html amp lang="en">
  <head>

    <meta charset="utf-8">
    <title>Fallacies of AI Driven Coding</title>
    <link rel="canonical" href="https://www.yegor256.com/2022/02/16/ai-coding.html">
    <link rel="icon" type="image/png" href="/favicon.ico">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage":{
          "@type": "WebPage",
          "@id": "https://www.yegor256.com/2022/02/16/ai-coding.html"
        },
        "headline": "Fallacies of AI Driven Coding",
        "image": {
          "@type": "ImageObject",
          "url": "/images/2022/02/short-circuit.jpg",
          "height": 952,
          "width": 1500
        },
        "datePublished": "2022-02-16",
        "dateModified": "2022-02-16",
        "author": {
          "@type": "Person",
          "name": "Yegor Bugayenko"
        },
        "publisher": {
          "@type": "Organization",
          "name": "yegor256.com",
          "logo": {
            "@type": "ImageObject",
            "url": "https://www.yegor256.com/images/face-512x512.jpg",
            "width": 512,
            "height": 512
          }
        },
        "description": "AI will eventually replace programmers? AlphaCode and Codex
are two best examples of coder killers? I don't think so.
",
        "keywords": ["ai coder", "ai programmer", "codex", "alphacode", "ai coding"]
      }
    </script>
    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style>
<noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500">
    <style amp-custom="amp-custom">
      @font-face {
        font-family: 'Cambria';
        src: url('https://www.yegor256.com/fonts/cambria/2EAA54_2_0.ttf');
      }
      body { font-family: 'Cambria', 'Times New Roman', serif; padding: .5em; font-size: 1.2em; }
      article { width: 600px; max-width: 100%; margin-left: auto; margin-right: auto; }
      pre, code { font-family: 'Source Code Pro', 'Courier New', monospace; font-size: .8em; }
      code { padding: 0 .3em; background-color: lightgray; }
      a, a:hover, a:visited { color: inherit; }
      .intro { color: red; font-size: .75em; }
      .photo { border-radius: 50%; }
      pre { overflow-x:scroll; }
    </style>
    <script async src="https://cdn.ampproject.org/v0.js"></script>
  </head>
  <body>
    <article>
      <p class="intro">
        This is a mobile version, full one is
        <a href="https://www.yegor256.com/2022/02/16/ai-coding.html">here</a>.
      </p>
      <p>
        <amp-img src="/images/face-256x256.jpg" width="80" height="80" alt="Yegor Bugayenko" class="photo"></amp-img>
      </p>
      <p>Yegor Bugayenko<br>16 February 2022</p>
      <h1>Fallacies of AI Driven Coding</h1>
      <p>A few days ago, <a href="https://deepmind.com">DeepMind</a>
(<a href="https://techcrunch.com/2014/01/26/google-deepmind/">acquired</a> by Google in 2014) released
<a href="https://alphacode.deepmind.com">AlphaCode</a> and self-published
a
<a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">paper</a>
explaining how their artificial intelligence (AI) can “understand”
a programming contest task written in English and then write a Python, Java or C++ program, which
would work in about 30% of cases.
Earlier last year <a href="https://en.wikipedia.org/wiki/OpenAI">OpenAI</a>
(<a href="https://openai.com/blog/microsoft/">$1B-funded</a> by Microsoft in 2019)
released <a href="https://openai.com/blog/openai-codex/">Codex</a>
and published a <a href="https://arxiv.org/abs/2107.03374">paper</a>, claiming
that their AI can also solve around 30% of the programming tasks it was
tested with.
<a href="https://www.wired.com/story/ai-write-code-like-humans-bugs/">Wired</a>,
the <a href="https://www.ft.com/content/65477c33-cb72-418d-b03d-b60cfc5a8b5d">Financial Times</a>,
<a href="https://www.theverge.com/2022/2/2/22914085/alphacode-ai-coding-program-automatic-deepmind-codeforce">The Verge</a>
and many others have already announced the victory:
AI <a href="https://www.bbc.com/news/business-57914432">will replace programmers</a>
and we are all going to lose our jobs.</p>



<amp-img src="/images/2022/02/short-circuit.jpg" alt="Short Circuit (1986) by John Badham" height="952" width="1500" layout="responsive"></amp-img>

<p>I would identify five beliefs about AI and its code-writing abilities,
which, in my opinion, are fundamental fallacies:</p>

<ul>
  <li>
    <p><strong>AI writes code (NOT!)</strong><br>
It’s not true.
Neither AlphaCode nor Codex <em>write</em> code. Instead, they <em>find</em> it.
According to the AlphaCode paper, “generating code that solves a specific task
requires <em>searching</em> in a huge structured space of programs.”
Even though Machine Learning (ML) makes searching
faster, it doesn’t make it writing. As far as I understand (the paper
is pretty vague on the exact details of model training), they turn
descriptions of programming tasks into sequences of numbers (tokenized characters!)
and then label them with solutions found … in GitHub or
<a href="https://codeforces.com">Codeforces</a> open repositories.
Then they ask the model to find the best solution for the vector of characters
in question. Saying that they write code is similar to saying that
Google draws pictures of cats when I search for a “black cat.”</p>
  </li>
  <li>
    <p><strong>AI understands requirements in a natural language (NOT!)</strong><br>
It doesn’t really <em>understand</em> anything.
Neither AlphaCode nor Codex analyze the <em>semantics</em> of the input. Whether it
says “draw a green line” or “save a file,” the AI sees just two sequences of characters:
of length 17 and 11 respectively. It doesn’t <em>know</em> what “green” means nor how it’s different
from a “file.” They tokenize text into vectors. If they used
<a href="https://en.wikipedia.org/wiki/Controlled_natural_language">CNL</a> it would
be understanding, but they don’t.</p>
  </li>
  <li>
    <p><strong>AI pair-programs with a human (NOT!)</strong><br>
We may expect AI not to entirely replace us programmers, but instead help us
write certain blocks of code: <a href="https://copilot.github.com">Copilot</a>
(<a href="https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/">released</a>
by <a href="https://github.com">GitHub</a> in 2021)
is a notable example, <a href="https://hackernoon.com/openais-new-code-generator-github-copilot-and-codex-bb143773">powered</a>
by the same Codex. A few months ago I got an early access to Codex and played a bit with
its features. My impression, as a programmer, was that it was neither able to
write an entire program nor did the blocks of
code it produced in response to my requests fit together. They were syntactically
valid and implemented the functionality requested, but the AI was falling short in combining
them the way I, a human, might agree to maintain them later.</p>
  </li>
  <li>
    <p><strong>AI autocompletes, that’s why they can write (NOT!)</strong><br>
Indeed, there are a few products which do code autocompletion
with the use of ML, for example <a href="https://www.codota.com">Codota</a>,
<a href="https://www.tabnine.com">Tabnine</a>,
and
<a href="https://www.kite.com">Kite</a>.
However, they don’t work with natural languages.
These are two different research problems:
1) how to <a href="https://en.wikipedia.org/wiki/Autocomplete">autocomplete</a>
an existing program with known
functionality and an already existing <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a>,
and
2) how to turn natural language text into an AST.
As far as I understand, they don’t and never will overlap.</p>
  </li>
  <li>
    <p><strong>AI just needs time to mature (NOT!)</strong><br>
<a href="https://spectrum.ieee.org/openai-wont-replace-coders">Some</a> believe
that AI will replace programmers, but “that day won’t arrive any time soon.”
However, it seems to me that it’s not a matter of maturity. The very
direction researchers of OpenAI and DeepMind are trying to pursue is a dead end.
ML is just not the right tool to turn unstructured English text into a well-structured
AST which is parseable by C++ compiler. To do this we need the AI to
learn the semantics of the natural language and then, using
<em>creativity</em> and <em>imagination</em>,
create all necessary AST elements in the right order.
I simply don’t believe that ML is the right technology for this.</p>
  </li>
</ul>

<p>To conclude, ML will never write our code, because … it’s just not
the right tool for the job.
However, it may be suitable for other things, like autocompletion,
refactoring, bug fixing, optimization, and so on. I’m particularly interested
in automated refactoring: imagine a large legacy code base given to AI,
which improves certain parts of it, making the code faster,
safer, more readable, or shorter. Maybe it will even upgrade the code to newer frameworks, SDKs,
and dependencies. This is where ML already helps and will help more,
improving <em>existing</em> ASTs.</p>



<p>Trying to apply ML to code generating is a road to nowhere, which
only wastes resources and … boosts stocks of Google and Microsoft.</p>

<p>Besides, how much good will it do to the industry if programmers write
code mostly by finding samples on the Internet, copying, and sticking them together?
Many of them already do that even without AI.
The <a href="https://stackoverflow.blog/2021/12/30/how-often-do-people-actually-copy-and-paste-from-stack-overflow-now-we-know/">analysis</a>
recently done by Stack Overflow demonstrates that “the higher a user’s reputation,
the less often they are copying.” Less skillful programmers tend to copy.
Is this a good tendency? Do we want AI to push it further?</p>

<p>Will AI ever be able to write code by reading natural language requirements?
Yes, it will. When we invent artificial creativity.</p>

    </article>
  </body>
</html>
