<!doctypehtml><html amp lang="en"><meta charset="utf-8"><title>Fast Tests Help Humans, Deep Tests Help Servers</title><link rel="canonical"href="https://www.yegor256.com/2023/08/22/fast-vs-deep-testing.html"><link rel="icon"type="image/png"href="/favicon.ico"><meta name="viewport"content="width=device-width,minimum-scale=1,initial-scale=1"><script type="application/ld+json">{
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage":{
          "@type": "WebPage",
          "@id": "https://www.yegor256.com/2023/08/22/fast-vs-deep-testing.html"
        },
        "headline": "Fast Tests Help Humans, Deep Tests Help Servers",
        "image": {
          "@type": "ImageObject",
          "url": "/images/2023/08/inglourious-basterds.jpg",
          "height": 675,
          "width": 1200
        },
        "datePublished": "2023-08-22",
        "dateModified": "2023-08-22",
        "author": {
          "@type": "Person",
          "name": "Yegor Bugayenko"
        },
        "publisher": {
          "@type": "Organization",
          "name": "yegor256.com",
          "logo": {
            "@type": "ImageObject",
            "url": "https://www.yegor256.com/images/face-512x512.jpg",
            "width": 512,
            "height": 512
          }
        },
        "description": "Humans should run "fast" tests to catch obvious mistakes, while
servers should execute "deep" tests to ensure the highest quality.
",
        "keywords": ["fast tests", "unit tests", "thorough tests", "slow tests", "fast tests"]
      }</script><style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript><link rel="stylesheet"href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500"><style amp-custom="amp-custom">@font-face{font-family:Cambria;src:url(https://www.yegor256.com/fonts/cambria/2EAA54_2_0.ttf)}body{font-family:Cambria,'Times New Roman',serif;padding:.5em;font-size:1.2em}article{width:600px;max-width:100%;margin-left:auto;margin-right:auto}code,pre{font-family:'Source Code Pro','Courier New',monospace;font-size:.8em}code{padding:0 .3em;background-color:#d3d3d3}a,a:hover,a:visited{color:inherit}.intro{color:red;font-size:.75em}.photo{border-radius:50%}pre{overflow-x:scroll}</style><script async src="https://cdn.ampproject.org/v0.js"></script><article><p class="intro">This is a mobile version, full one is <a href="https://www.yegor256.com/2023/08/22/fast-vs-deep-testing.html">here</a>.<p><amp-img src="/images/face-256x256.jpg"width="80"height="80"alt="Yegor Bugayenko"class="photo"></amp-img><p>Yegor Bugayenko<br>22 August 2023<h1>Fast Tests Help Humans, Deep Tests Help Servers</h1><p>In order to reveal errors of higher complexity, automated tests are turned into integration tests that involve external resources in test scenarios, instead of their mocks. While this approach improves test coverage, it slows down the entire build pipeline. This compromises the very idea of automated tests, which are meant to be a <a href="/2022/07/05/safety-net.html">safety net</a> and help programmers edit code safely. Splitting the tests into “fast” and “deep,” and then allowing humans to run the former while servers run the latter, might be a good solution to the problem.</p><amp-img src="/images/2023/08/inglourious-basterds.jpg"alt="Inglourious Basterds (2009) by Quentin Tarantino"height="675"width="1200"layout="responsive"></amp-img><p>Consider this Java code with a simple <code class="language-plaintext highlighter-rouge">toString()</code> static method:<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">static</span> <span class="nc">String</span> <span class="nf">toString</span><span class="o">(</span><span class="nc">InputStream</span> <span class="n">stream</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
  <span class="kd">final</span> <span class="nc">StringBuilder</span> <span class="n">buf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StringBuilder</span><span class="o">();</span>
  <span class="k">while</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">d</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">read</span><span class="o">();</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">d</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">break</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">buf</span><span class="o">.</span><span class="na">append</span><span class="o">((</span><span class="kt">char</span><span class="o">)</span> <span class="n">d</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="k">return</span> <span class="n">buf</span><span class="o">.</span><span class="na">toString</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div></div><p>It reads the <code class="language-plaintext highlighter-rouge">stream</code> byte by byte, appends them to the buffer, and returns the buffer to the client. Here is the JUnit5 test that validates the functionality:<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Test</span>
<span class="kt">void</span> <span class="nf">readsSomeData</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
  <span class="nc">Assertions</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span>
    <span class="s">"ABC"</span><span class="o">,</span>
    <span class="n">toString</span><span class="o">(</span>
      <span class="k">new</span> <span class="nf">ByteArrayInputStream</span><span class="o">(</span>
        <span class="k">new</span> <span class="kt">byte</span><span class="o">[]</span> <span class="o">{</span><span class="mh">0x41</span><span class="o">,</span> <span class="mh">0x42</span><span class="o">,</span> <span class="mh">0x43</span><span class="o">}</span>
      <span class="o">)</span>
    <span class="o">)</span>
  <span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div><p>So far, so good. The test works, and the method seems to be correct. Moreover, the test completes very quickly—just 5ms on my laptop. However, upon closer inspection, we can identify a bug in the method: it doesn’t close the input stream. This issue doesn’t impact the test because the input stream is in memory and doesn’t hold any valuable resources that might leak. However, if we introduce a new test, it will expose this problem:<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Test</span>
<span class="kt">void</span> <span class="nf">readsFromManyFiles</span><span class="o">(</span><span class="nd">@TempDir</span> <span class="nc">Path</span> <span class="n">tmp</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
  <span class="nc">Path</span> <span class="n">f</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="na">resolve</span><span class="o">(</span><span class="s">"test.txt"</span><span class="o">);</span>
  <span class="nc">Files</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">f</span><span class="o">,</span> <span class="s">"Hello, world!"</span><span class="o">.</span><span class="na">getBytes</span><span class="o">());</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">20000</span><span class="o">;</span> <span class="o">++</span><span class="n">i</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">Assertions</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span>
      <span class="mi">13</span><span class="o">,</span>
      <span class="n">toString</span><span class="o">(</span><span class="k">new</span> <span class="nc">FileInputStream</span><span class="o">(</span><span class="n">f</span><span class="o">.</span><span class="na">toFile</span><span class="o">())).</span><span class="na">length</span><span class="o">()</span>
    <span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div><p>When I run this test, I get a <code class="language-plaintext highlighter-rouge">FileNotFoundException</code> with a message saying <code class="language-plaintext highlighter-rouge">Too many open files</code>. If I reduce the upper limit in the for loop to 10000, the error disappears. This most definitely happens because the maximum number of open files on Mac OS X <a href="https://superuser.com/a/443168">is 12,288</a>. However, on Ubuntu, this limit is <a href="https://askubuntu.com/questions/1049058">set to 65536</a>. Thus, my test won’t spot an error if I run it on Ubuntu. I’m sure you know how to fix this error in the toString() method.<p>Obviously, the second test is much slower than the first one, taking 650ms on my laptop (130 times slower!). This is just an example of a test that aids in bug detection but is time-consuming. Typically, integration tests demonstrate such a negative impact on performance because they involve “external” resources, which are slow. The file system, used by the second test, is one such external resource.<p>650ms might not be problematic when there are only a few test methods in a young project. However, as the number of tests increases, slow tests quickly become an issue since the overall build time lengthens, frustrating programmers. Automated tests, meant to assist coders, turn into a hindrance. If a coder has to wait several minutes after every code change to ensure nothing broke, frustration ensues. Often, the frustrated coder might remove those slow tests.<p>It goes without saying that deleting slow tests isn’t the solution. So, what is? Speeding them up? Not quite. It’s almost always challenging, if not impossible, to make integration tests faster since they are inherently slow for a reason. The only way to speed them up is to mock those slow external resources. But these resources are tested specifically to detect bugs that unit tests might miss. For instance, in our case, if we mock the input stream, the second test will miss the bug. Therefore, the second (integration) test must be slow to be valuable.<blockquote><p>Once the commit build is good then other people can work on the code with confidence. However there are further, slower, tests that we can start to do. Additional machines can run further testing routines on the build that take longer to do.—<a href="https://martinfowler.com/articles/continuousIntegration.html">Martin Fowler</a></blockquote><p>Classifying tests into <em>fast</em> and <em>deep</em> may be a solution. The first category comprises tests that mock as much as possible and take no more than 20ms to run. The second category consists of tests that probe deeper to uncover elusive bugs, which might be overlooked by faster tests. More often than not, unit tests fall into the first category, while integration tests fit into the second. The distinction of “unit-vs-integration” is, in my view, misleading. “Fast-vs-deep” is much clearer since it’s evident to which category a test belongs. If a test takes under 20ms, it’s fast; if not, it’s deep.<p>Once tests are designated as either fast or deep, they should be run in two distinct scenarios: programmers run the fast tests during coding, while servers execute the deep tests during software build and/or release phases. In JUnit5, this categorization can be achieved using the @Tag annotation:<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Test</span>
<span class="nd">@Tag</span><span class="o">(</span><span class="s">"fast"</span><span class="o">)</span>
<span class="kt">void</span> <span class="nf">readsSomeData</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
  <span class="c1">// ...</span>
<span class="o">}</span>
<span class="nd">@Test</span>
<span class="nd">@Tag</span><span class="o">(</span><span class="s">"deep"</span><span class="o">)</span>
<span class="kt">void</span> <span class="nf">readsFromManyFiles</span><span class="o">(</span><span class="nd">@TempDir</span> <span class="nc">Path</span> <span class="n">tmp</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
  <span class="c1">// ...</span>
<span class="o">}</span>
</code></pre></div></div><p>In most cases, obvious bugs will be detected by fast tests, giving programmers confidence when editing the code. On the rare occasions when fast tests fail to identify certain bugs, the deep tests will catch them. Only then will programmers run the slow tests on their laptops.<p>This is how <code class="language-plaintext highlighter-rouge">pom.xml</code> may be configured to turn “fast” tests ON, by default:<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;plugin&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>maven-surefire-plugin<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;groups&gt;</span>fast<span class="nt">&lt;/groups&gt;</span>
  <span class="nt">&lt;/configuration&gt;</span>
<span class="nt">&lt;/plugin&gt;</span>
</code></pre></div></div><p>In the CI environment, Maven must be started with the following flag:<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ mvn test -Dgroups=slow
</code></pre></div></div><p>A programmer can also run the “slow” tests on their own laptop using the same command line flag. However, this will typically only be done when the server issues a red signal.<p>P.S. By the way, the <code class="language-plaintext highlighter-rouge">toString()</code> method has another bug that isn’t detected by either the first or second test. Can you identify it? Could you devise a test that would expose this bug? Would you categorize this test as “fast” or “deep”?</article>